{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Cleaning text parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to import the corpus we've already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('whole_corpus.pickle', 'rb') as handle:\n",
    "    df_corpus = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look into the corpus and check if there are duplicated rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26797</td>\n",
       "      <td>26797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>24564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>DUE</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3860</td>\n",
       "      <td>1436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag       abstract\n",
       "count   26797          26797\n",
       "unique     10          24564\n",
       "top       DUE  Not Available\n",
       "freq     3860           1436"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus = df_corpus[df_corpus['abstract'] != 'Not Available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24563</td>\n",
       "      <td>24563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>24563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>DUE</td>\n",
       "      <td>Using SEEP II water column data and sedimentar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag                                           abstract\n",
       "count   24563                                              24563\n",
       "unique     10                                              24563\n",
       "top       DUE  Using SEEP II water column data and sedimentar...\n",
       "freq     3816                                                  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Search duplicates and keep only one from each\n",
    "for text,count in Counter(df_corpus['abstract']).items():\n",
    "    if count>1:\n",
    "        df_corpus.drop(list(df_corpus.index[df_corpus['abstract']==text])[1::],axis=0,inplace=True)\n",
    "        \n",
    "# Get a summary of data again\n",
    "display(df_corpus.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief preprocessing in order to make the text ready for the calculation. Here uniformative characters e.g. punctuations and non-alphabetical ones are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_sm\n",
    "\n",
    "def clean_text(col):\n",
    "    \n",
    "    col = col.str.replace('\\\\n',' ').str.lower()\n",
    "    col = col.str.replace('\\\\t',' ')\n",
    "    col = col.str.replace('_',' ')\n",
    "    col = col.str.replace('[^\\\\w\\\\s]',' ')\n",
    "    col = col.apply(lambda x: x.translate(str.maketrans(' ',' ',string.digits)))\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here three topics are selected, *'CHE'* stands for Chemistry, *'DMS'* for Mathematics and *'IBN'* for Biology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = ['CHE','DMS','IBN']\n",
    "df_corpus = df_corpus.loc[df_corpus['tag'].isin(tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus['abstract'] = clean_text(df_corpus['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then first lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "df_corpus['abstract_lemmatized'] = df_corpus.abstract.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally removing stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus['cleaned_abstract'] = df_corpus['abstract_lemmatized'].apply(lambda x: [item for item in x if item not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take a look into the dataset, in order to check later if there are comon frequent words in all categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "tokens_CHE = df_corpus['cleaned_abstract'][df_corpus['tag'] == 'CHE'].tolist()\n",
    "tokens_CHE = [item for sublist in tokens_CHE for item in sublist]\n",
    "frequent_CHE = [ii[0] for ii in Counter(tokens_CHE).most_common(50)]\n",
    "\n",
    "tokens_DMS = df_corpus['cleaned_abstract'][df_corpus['tag'] == 'DMS'].tolist()\n",
    "tokens_DMS = [item for sublist in tokens_DMS for item in sublist]\n",
    "frequent_DMS = [ii[0] for ii in Counter(tokens_DMS).most_common(50)]\n",
    "\n",
    "tokens_IBN = df_corpus['cleaned_abstract'][df_corpus['tag'] == 'IBN'].tolist()\n",
    "tokens_IBN = [item for sublist in tokens_IBN for item in sublist]\n",
    "frequent_IBN = [ii[0] for ii in Counter(tokens_IBN).most_common(50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all words of lenght less than 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa',\n",
       " 'ab',\n",
       " 'ac',\n",
       " 'ad',\n",
       " 'af',\n",
       " 'ag',\n",
       " 'ah',\n",
       " 'ai',\n",
       " 'ak',\n",
       " 'al',\n",
       " 'ap',\n",
       " 'ar',\n",
       " 'au',\n",
       " 'ax',\n",
       " 'az',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'bc',\n",
       " 'bf',\n",
       " 'bi',\n",
       " 'bl',\n",
       " 'bm',\n",
       " 'bn',\n",
       " 'bo',\n",
       " 'bp',\n",
       " 'br',\n",
       " 'bv',\n",
       " 'bx',\n",
       " 'bz',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'ce',\n",
       " 'cf',\n",
       " 'cg',\n",
       " 'ch',\n",
       " 'ci',\n",
       " 'cl',\n",
       " 'cm',\n",
       " 'cn',\n",
       " 'co',\n",
       " 'cp',\n",
       " 'cr',\n",
       " 'ct',\n",
       " 'cu',\n",
       " 'cv',\n",
       " 'cw',\n",
       " 'cx',\n",
       " 'cy',\n",
       " 'da',\n",
       " 'db',\n",
       " 'dc',\n",
       " 'dd',\n",
       " 'de',\n",
       " 'df',\n",
       " 'dh',\n",
       " 'di',\n",
       " 'dl',\n",
       " 'dm',\n",
       " 'dp',\n",
       " 'dr',\n",
       " 'dt',\n",
       " 'du',\n",
       " 'dy',\n",
       " 'dz',\n",
       " 'e',\n",
       " 'ea',\n",
       " 'ec',\n",
       " 'ed',\n",
       " 'ee',\n",
       " 'eg',\n",
       " 'eh',\n",
       " 'ei',\n",
       " 'el',\n",
       " 'em',\n",
       " 'en',\n",
       " 'eq',\n",
       " 'er',\n",
       " 'es',\n",
       " 'et',\n",
       " 'eu',\n",
       " 'ev',\n",
       " 'ew',\n",
       " 'ex',\n",
       " 'ez',\n",
       " 'eõ',\n",
       " 'f',\n",
       " 'fa',\n",
       " 'fc',\n",
       " 'fe',\n",
       " 'fh',\n",
       " 'fj',\n",
       " 'fk',\n",
       " 'fl',\n",
       " 'fm',\n",
       " 'fn',\n",
       " 'fo',\n",
       " 'ft',\n",
       " 'fu',\n",
       " 'fv',\n",
       " 'fx',\n",
       " 'fy',\n",
       " 'g',\n",
       " 'ga',\n",
       " 'gb',\n",
       " 'gc',\n",
       " 'gd',\n",
       " 'ge',\n",
       " 'gf',\n",
       " 'gh',\n",
       " 'gi',\n",
       " 'gl',\n",
       " 'gm',\n",
       " 'gn',\n",
       " 'go',\n",
       " 'gp',\n",
       " 'gr',\n",
       " 'gt',\n",
       " 'gu',\n",
       " 'gx',\n",
       " 'h',\n",
       " 'ha',\n",
       " 'hb',\n",
       " 'hd',\n",
       " 'hf',\n",
       " 'hg',\n",
       " 'hh',\n",
       " 'hi',\n",
       " 'ho',\n",
       " 'hp',\n",
       " 'hr',\n",
       " 'ht',\n",
       " 'hu',\n",
       " 'hy',\n",
       " 'hz',\n",
       " 'ia',\n",
       " 'ic',\n",
       " 'id',\n",
       " 'ii',\n",
       " 'il',\n",
       " 'im',\n",
       " 'io',\n",
       " 'ip',\n",
       " 'ir',\n",
       " 'iv',\n",
       " 'ix',\n",
       " 'j',\n",
       " 'jc',\n",
       " 'jh',\n",
       " 'ji',\n",
       " 'jp',\n",
       " 'jr',\n",
       " 'k',\n",
       " 'ka',\n",
       " 'kb',\n",
       " 'kc',\n",
       " 'kd',\n",
       " 'kg',\n",
       " 'kh',\n",
       " 'kj',\n",
       " 'kk',\n",
       " 'kl',\n",
       " 'km',\n",
       " 'kn',\n",
       " 'kp',\n",
       " 'kx',\n",
       " 'kõ',\n",
       " 'l',\n",
       " 'la',\n",
       " 'lb',\n",
       " 'lc',\n",
       " 'ld',\n",
       " 'le',\n",
       " 'lg',\n",
       " 'lh',\n",
       " 'li',\n",
       " 'ln',\n",
       " 'lo',\n",
       " 'lp',\n",
       " 'lr',\n",
       " 'lu',\n",
       " 'lw',\n",
       " 'ly',\n",
       " 'mb',\n",
       " 'mc',\n",
       " 'md',\n",
       " 'mf',\n",
       " 'mg',\n",
       " 'mi',\n",
       " 'mk',\n",
       " 'ml',\n",
       " 'mm',\n",
       " 'mn',\n",
       " 'mo',\n",
       " 'mp',\n",
       " 'mr',\n",
       " 'mt',\n",
       " 'mu',\n",
       " 'mw',\n",
       " 'mx',\n",
       " 'n',\n",
       " 'na',\n",
       " 'nb',\n",
       " 'nc',\n",
       " 'nd',\n",
       " 'ne',\n",
       " 'nf',\n",
       " 'ng',\n",
       " 'nh',\n",
       " 'ni',\n",
       " 'nm',\n",
       " 'nn',\n",
       " 'np',\n",
       " 'nr',\n",
       " 'nt',\n",
       " 'nu',\n",
       " 'nw',\n",
       " 'nx',\n",
       " 'ny',\n",
       " 'oc',\n",
       " 'od',\n",
       " 'oe',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'om',\n",
       " 'oo',\n",
       " 'ot',\n",
       " 'oz',\n",
       " 'p',\n",
       " 'pa',\n",
       " 'pb',\n",
       " 'pc',\n",
       " 'pd',\n",
       " 'pe',\n",
       " 'pf',\n",
       " 'pg',\n",
       " 'ph',\n",
       " 'pi',\n",
       " 'pl',\n",
       " 'pm',\n",
       " 'pn',\n",
       " 'po',\n",
       " 'pp',\n",
       " 'pr',\n",
       " 'pt',\n",
       " 'pv',\n",
       " 'pz',\n",
       " 'q',\n",
       " 'qc',\n",
       " 'qm',\n",
       " 'qq',\n",
       " 'qr',\n",
       " 'qu',\n",
       " 'r',\n",
       " 'ra',\n",
       " 'rb',\n",
       " 'rd',\n",
       " 'rf',\n",
       " 'rg',\n",
       " 'rh',\n",
       " 'ri',\n",
       " 'rj',\n",
       " 'rk',\n",
       " 'rm',\n",
       " 'rn',\n",
       " 'ro',\n",
       " 'rr',\n",
       " 'rt',\n",
       " 'ru',\n",
       " 'rv',\n",
       " 'ry',\n",
       " 'sa',\n",
       " 'sb',\n",
       " 'sc',\n",
       " 'sd',\n",
       " 'se',\n",
       " 'sg',\n",
       " 'sh',\n",
       " 'si',\n",
       " 'sj',\n",
       " 'sl',\n",
       " 'sm',\n",
       " 'sn',\n",
       " 'sp',\n",
       " 'sr',\n",
       " 'st',\n",
       " 'su',\n",
       " 'sw',\n",
       " 'sy',\n",
       " 'sz',\n",
       " 'ta',\n",
       " 'tc',\n",
       " 'te',\n",
       " 'tf',\n",
       " 'tg',\n",
       " 'th',\n",
       " 'ti',\n",
       " 'tk',\n",
       " 'tl',\n",
       " 'tm',\n",
       " 'tp',\n",
       " 'tu',\n",
       " 'tv',\n",
       " 'tw',\n",
       " 'tx',\n",
       " 'u',\n",
       " 'ub',\n",
       " 'uc',\n",
       " 'uh',\n",
       " 'um',\n",
       " 'un',\n",
       " 'us',\n",
       " 'uv',\n",
       " 'v',\n",
       " 'va',\n",
       " 'vc',\n",
       " 'vg',\n",
       " 'vi',\n",
       " 'vl',\n",
       " 'vm',\n",
       " 'vn',\n",
       " 'vp',\n",
       " 'vr',\n",
       " 'vt',\n",
       " 'w',\n",
       " 'wa',\n",
       " 'wd',\n",
       " 'wh',\n",
       " 'wi',\n",
       " 'wm',\n",
       " 'wn',\n",
       " 'wu',\n",
       " 'x',\n",
       " 'xc',\n",
       " 'xe',\n",
       " 'xf',\n",
       " 'xh',\n",
       " 'xi',\n",
       " 'xl',\n",
       " 'xp',\n",
       " 'xu',\n",
       " 'xx',\n",
       " 'xy',\n",
       " 'ya',\n",
       " 'ye',\n",
       " 'yl',\n",
       " 'yu',\n",
       " 'yy',\n",
       " 'z',\n",
       " 'zf',\n",
       " 'zg',\n",
       " 'zn',\n",
       " 'zo',\n",
       " 'zp',\n",
       " 'zr',\n",
       " 'zy',\n",
       " 'õ'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([ii for cell in df_corpus['cleaned_abstract'].tolist() for ii in cell if len(ii)<3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus['cleaned_abstract'] = df_corpus['cleaned_abstract'].apply(lambda x: [s for s in x if len(s) > 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a new column to save cleand abstracts as text: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corpus['cleaned_abstract'] = df_corpus['cleaned_abstract'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_lemmatized</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a9000038.txt</th>\n",
       "      <td>DMS</td>\n",
       "      <td>this research is part of an on going program b...</td>\n",
       "      <td>[this, research, is, part, of, an, on, going, ...</td>\n",
       "      <td>research part going program principal investig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000053.txt</th>\n",
       "      <td>DMS</td>\n",
       "      <td>the mathematical theories of multivariate poly...</td>\n",
       "      <td>[the, mathematical, theory, of, multivariate, ...</td>\n",
       "      <td>mathematical theory multivariate polynomial in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000054.txt</th>\n",
       "      <td>DMS</td>\n",
       "      <td>work to be done during the period of this awar...</td>\n",
       "      <td>[work, to, be, done, during, the, period, of, ...</td>\n",
       "      <td>work done period award focus higher dimensiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000075.txt</th>\n",
       "      <td>IBN</td>\n",
       "      <td>in collaboration with costa rican graduate stu...</td>\n",
       "      <td>[in, collaboration, with, costa, rican, gradua...</td>\n",
       "      <td>collaboration costa rican graduate student sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000094.txt</th>\n",
       "      <td>IBN</td>\n",
       "      <td>the continued destruction of the coastal and t...</td>\n",
       "      <td>[the, continued, destruction, of, the, coastal...</td>\n",
       "      <td>continued destruction coastal tropical forest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tag                                           abstract  \\\n",
       "a9000038.txt  DMS  this research is part of an on going program b...   \n",
       "a9000053.txt  DMS  the mathematical theories of multivariate poly...   \n",
       "a9000054.txt  DMS  work to be done during the period of this awar...   \n",
       "a9000075.txt  IBN  in collaboration with costa rican graduate stu...   \n",
       "a9000094.txt  IBN  the continued destruction of the coastal and t...   \n",
       "\n",
       "                                            abstract_lemmatized  \\\n",
       "a9000038.txt  [this, research, is, part, of, an, on, going, ...   \n",
       "a9000053.txt  [the, mathematical, theory, of, multivariate, ...   \n",
       "a9000054.txt  [work, to, be, done, during, the, period, of, ...   \n",
       "a9000075.txt  [in, collaboration, with, costa, rican, gradua...   \n",
       "a9000094.txt  [the, continued, destruction, of, the, coastal...   \n",
       "\n",
       "                                               cleaned_abstract  \n",
       "a9000038.txt  research part going program principal investig...  \n",
       "a9000053.txt  mathematical theory multivariate polynomial in...  \n",
       "a9000054.txt  work done period award focus higher dimensiona...  \n",
       "a9000075.txt  collaboration costa rican graduate student sci...  \n",
       "a9000094.txt  continued destruction coastal tropical forest ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding common frequent words between all categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research\n",
      "study\n",
      "new\n",
      "project\n",
      "system\n",
      "important\n",
      "work\n"
     ]
    }
   ],
   "source": [
    "common_words = []\n",
    "for ii in frequent_CHE:\n",
    "    if ii in frequent_DMS and ii in frequent_IBN:\n",
    "        print(ii)\n",
    "        common_words.append(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As those common words may affect the model negatively, we are going to remove them from the abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ii in common_words:\n",
    "    df_corpus['cleaned_abstract'] = df_corpus['cleaned_abstract'].apply(lambda x: x.replace(ii, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a9000038.txt</th>\n",
       "      <td>DMS</td>\n",
       "      <td>this research is part of an on going program b...</td>\n",
       "      <td>part going program principal investigator ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000053.txt</th>\n",
       "      <td>DMS</td>\n",
       "      <td>the mathematical theories of multivariate poly...</td>\n",
       "      <td>mathematical theory multivariate polynomial in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000054.txt</th>\n",
       "      <td>DMS</td>\n",
       "      <td>work to be done during the period of this awar...</td>\n",
       "      <td>done period award focus higher dimensional in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000075.txt</th>\n",
       "      <td>IBN</td>\n",
       "      <td>in collaboration with costa rican graduate stu...</td>\n",
       "      <td>collaboration costa rican graduate student sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9000094.txt</th>\n",
       "      <td>IBN</td>\n",
       "      <td>the continued destruction of the coastal and t...</td>\n",
       "      <td>continued destruction coastal tropical forest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tag                                           abstract  \\\n",
       "a9000038.txt  DMS  this research is part of an on going program b...   \n",
       "a9000053.txt  DMS  the mathematical theories of multivariate poly...   \n",
       "a9000054.txt  DMS  work to be done during the period of this awar...   \n",
       "a9000075.txt  IBN  in collaboration with costa rican graduate stu...   \n",
       "a9000094.txt  IBN  the continued destruction of the coastal and t...   \n",
       "\n",
       "                                               cleaned_abstract  \n",
       "a9000038.txt   part going program principal investigator ass...  \n",
       "a9000053.txt  mathematical theory multivariate polynomial in...  \n",
       "a9000054.txt   done period award focus higher dimensional in...  \n",
       "a9000075.txt  collaboration costa rican graduate student sci...  \n",
       "a9000094.txt  continued destruction coastal tropical forest ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display \n",
    "df_corpus.drop('abstract_lemmatized',axis=1, inplace=True)\n",
    "display(df_corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>7895</td>\n",
       "      <td>7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>DMS</td>\n",
       "      <td>this award will fund a mathematical sciences r...</td>\n",
       "      <td>award support development computer software  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3672</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag                                           abstract  \\\n",
       "count   7896                                               7896   \n",
       "unique     3                                               7895   \n",
       "top      DMS  this award will fund a mathematical sciences r...   \n",
       "freq    3672                                                  2   \n",
       "\n",
       "                                         cleaned_abstract  \n",
       "count                                                7896  \n",
       "unique                                               7888  \n",
       "top     award support development computer software  e...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it's shown above, there are some duplicated rows in the dataset, which must be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for text,count in Counter(df_corpus['cleaned_abstract']).items():\n",
    "    if count>1:\n",
    "        df_corpus.drop(list(df_corpus.index[df_corpus['cleaned_abstract']==text])[1::],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7888</td>\n",
       "      <td>7888</td>\n",
       "      <td>7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>7888</td>\n",
       "      <td>7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>DMS</td>\n",
       "      <td>in this project in the physical chemistry prog...</td>\n",
       "      <td>grand challenge application group competition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3666</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag                                           abstract  \\\n",
       "count   7888                                               7888   \n",
       "unique     3                                               7888   \n",
       "top      DMS  in this project in the physical chemistry prog...   \n",
       "freq    3666                                                  1   \n",
       "\n",
       "                                         cleaned_abstract  \n",
       "count                                                7888  \n",
       "unique                                               7888  \n",
       "top     grand challenge application group competition ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prevent redoing cleaning part, the data is saved as a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('corpus_lemmatized.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_corpus, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
